
In the previous chapter, the shields were typically assumed to be aware of and be able to affect all the agents in the system instantaneously \cite{multiagentshield}.. However,
global information on the state of all the agents is often difficult to obtain in multi-agent systems. There has been some work in relaxing these assumptions using \emph{localized shields} that have awareness and authority over only the agents in their local region. However, no genuinely \emph{decentralized} approach, in which a shield onboard each agent can modify only the corresponding agent's behavior, exists ~\cite{BharNFM}. In such an approach, there would be no entity that has global information on the state space of the entire system. 

Without global information of the state, guaranteeing safety is, in general, undecidable~\cite{Schewe08}. Thus, we focus solely on enforcing \emph{local} safety properties, which is a subset of general temporal safety properties. A safety property is local if it can be enforced in the entire multi-agent system by enforcing it within each communication group. 
Essentially, shields are partial functions from the current states of the agents to the next states. 
Existing methods find this partial function by solving a reactive synthesis problem at design time~\cite{BloemKKW15,BharNFM,multiagentshield}. However, it is computationally prohibitive in the case of multi-agent systems since the resulting safety game has to take into account all possible behaviors from every agent \cite{BharNFM}. 

We formulate the synthesis of modified safe behavior of an agent as a graph search problem. More specifically, we assume agents know the intended behaviors of the other agents in its communication group and hence, an onboard enforcer can modify an agent's behavior, taking into account the behavior of the other agents in the same group. If the system continues to remain unsafe after the agent has changed its behavior, then the other agents are forced to change their behaviors. Thus, the synthesis of safe behavior for all agents in a communication group can be framed as a sequence of graph searches. This technique is similar to hierarchical path planning~\cite{Silver2005Jun}. In particular, we synthesize safe behavior online when required, i.e., when the intended trajectories of the agents violates a safety requirement. However, such an online approach to synthesizing new behaviors may create scenarios where some agents may never progress. That is, the behaviors of some agents may be perpetually modified to ensure safety.

In this chapter, we present a novel \emph{decentralized} framework for \emph{online} synthesis for runtime enforcement. The enforcer onboard each agent issues modifications to the behavior of its corresponding agent in an order according to their \emph{priority} using graph search.
The framework uses a novel decentralized \emph{ordering mechanism} to dynamically maintain the agent's priorities to ensure that every agent can make progress according to their intended behaviors. We assume that the agents have agreed on this mechanism. Additionally, it is possible to compute the order between any two agents (the total order relation corresponding to the priorities) on the fly using only the flags that are local to the two agents. Moreover, only the corresponding agents can modify these flags. The presented ordering mechanism provably guarantees that every agent can acquire the highest priority in a finite length of time; hence live-locks are avoided. The online synthesis approach performs local behavior modification as needed, this circumvents the state-space explosion.

\section{Related work}
The proposed approach is similar to \emph{cooperative path planning} in multi-agent systems, which is a PSPACE-hard problem~\cite{Hopcroft1984Dec}. Hierarchical cooperative A* (HCA*) is a decentralized approach that uses fixed priorities on agents and makes a plan for an agent while respecting the plans of the agents with higher priorities~\cite{Silver2005Jun}. However, HCA* may require the agents to change their plan continuously and, therefore, cannot guarantee finite-time progress \cite{Silver2005Jun}. Proposed approaches that achieve completeness and produce optimal paths~\cite{Standley2010Jul,Standley2011} are either non-tractable or rely on global information. The method in \cite{Zhang2016} relaxes the reliance on global information; however, it still falls back to using it as a last resort. Additionally, if the agents in the system can idle, we provide a condition that guarantees \emph{completeness}. That is, if there exists a safe behavior then the enforcer can guarantee safety. This level of decentralization, while ensuring system-level safety, is possible because the decentralized priority exchange mechanism we present ensures the absence of live-locks. In the existing techniques, live-locks have to be detected which requires global information. 

We evaluate the performance of the decentralized enforcer framework in the specific context of collision avoidance for multi-agent systems.
Collision avoidance is a well-studied topic. In \cite{Zhu2020AdaptiveOD}, an online reinforcement learning method is used for path planning. 
In \cite{Zhu2019}, a discriminative classifier that is used to map gas distribution, is trained online. An entropy-based artificial potential field or entropy-based particle swarm optimization algorithm is used in conjunction with the classifier for path planning. In contrast with the above techniques, the method in this chapter modifies the trajectories of the agents only when collisions are detected. Additionally, the method guarantees progress, i.e., no single agent keeps deviating continuously to keep the system collision free. 
 
In \cite{Rudd2017}, a distributed optimal control method based on the generalized reduced gradient is used for path planning. However, the method provides no guarantees for completeness. In contrast, we ensure a path exists if a centralized enforcer (referred to as a shield in ~\cite{BharNFM}) is able to find a path. More specifically, under certain assumptions, the technique in this chapter will synthesize decentralized enforcers that guarantee safety for all agents if there is a centralized enforcer that can guarantee safety. %However, this method can replace the local search for paths by the enforcer. The ordering mechanism then can ensure that the agents progress.
In contrast to \cite{AlAbri2020ADO}, the environment in this chapter is a discrete graph, and the agents take one unit of time to move from one location to the next location, i.e., the agents have uniform dynamics that do not depend on their location. These restriction enables to ensure progress and completeness.


\section{Contributions} To our best knowledge, this work in this chapter presents the first approach where the enforcement of safety properties is viewed through the lens of cooperative path planning. The existing formulation for runtime enforcement through shielding uses reactive systems. However, this is unsuitable and cumbersome for the online approach.  Therefore, we provide a new formulation where the enforcers are tuples of partial functions. An extra benefit of such an approach is that the \emph{joint} behavior of all the agents can be directly expressed as a functional composition. Lastly, we prove the resulting enforcers also satisfy the following properties \cite{bloem2014sat}:
\begin{enumerate}
    \item \emph{Correctness}: The modified system behavior satisfies all the safety properties,
    \item \emph{Minimal Deviation}:  If there is no safety violation among the agents in a communication group, then the enforcers on the agents in the group must not modify the behavior of the agents,
    \item \emph{Boundedness}:  The deviation from the original behavior must be finite. We additionally show that the maximum deviation is linear in the number of agents and
    \item \emph{Completeness}:  If a centralized stabilizing shield can guarantees correctness, the enforcers will also guarantee~correctness. 
\end{enumerate}
By construction, the enforcers do not require global information. Additionally, we prove that the worst-case synthesis time for each agent is at most quadratic in the number of agents.  

