
%A framework is needed in which humans can easily specify desirable high-level qualitative behaviour for autonomous systems performing complex tasks.
In this chapter, we investigate these questions in the context of autonomous agents that perform \emph{surveillance} tasks, that is, tracking the location of a target. 


Performing autonomous surveillance has many applications. If the target is adversarial, these applications include patrolling and security, especially in combination with other objectives, such as providing certain services or accomplishing a mission. For example, unmanned aerial vehicles (UAVs) are increasingly being adopted for monitoring of illegal hunting and poaching \cite{poaching}. In countries such as Kenya, South Africa, and Zimbabwe \cite{drones}, drones have been deployed and tested in an attempt to reduce poaching by providing continuous surveillance \cite{poaching}. However, all of these solutions still require a pilot to remotely operate the UAV or manually provide it with waypoints to follow. Autonomous surveillance has the potential to help combat poaching by drastically reducing manpower requirements. 

Autonomous surveillance also has many applications where the targets are not adversarial, but are unpredictable. One such example involves mobile luggage carrying robots in airports that are required to follow a human despite unpredictable motion and possibly sporadically losing sight of the target \cite{GonBanos02}. 

When dealing with an adversarial and/or unpredictable moving target, a strategy for the surveying agent to achieve its objective can be seen as a strategy in a two-player game between the agent and the target. Since the agent may not always observe, or even know, the exact location of the target, surveillance is, by its very nature, a partial-information problem.
It is thus natural to reduce surveillance strategy synthesis to computing a winning strategy for the agent in a two-player partial-information game. Game-based models for related problems have been extensively studied in the literature. Notable examples include pursuit-evasion games~\cite{Chung2011}, patrolling games~\cite{Basilico12}, and graph-searching games~\cite{Kreutzer11}, where the problem is formulated as enforcing eventual detection, which is, in its essence a search problem -- once the target is detected, the game ends. For many applications, this formulation is too restrictive. Often, the goal is not to detect or capture the target, but to maintain certain level of knowledge about its location over an unbounded time duration, or, alternatively, be able to obtain sufficiently precise information over and over again. In other cases, the agent may have an additional objective, such as performing a certain task, which might prevent it from capturing the target, but allow for satisfying a more relaxed surveillance objective.

In this paper, we study the problem of synthesizing strategies for enforcing \emph{quantitative temporal surveillance objectives}, such as the requirement to never let the agent's uncertainty about the target's location exceed a given threshold, or recapturing the target every time it escapes. To this end, we consider surveillance objectives specified in linear temporal logic (LTL), equipped with basic surveillance predicates. This formulation also allows for a seamless combination with other task specifications.

We model the problem as a two-player game played on a finite graph, whose nodes represent the possible locations of the agent and the target, and whose edges model the possible (deterministic) moves between locations. The agent plays the game with partial information, as it can only observe the target when  it is in range of its sensors. The target, on the other hand, always has full information about the agent's location, even when the agent is not in sight. In that way, we consider a game with one-sided partial information, making the computed strategy for the agent robust against a potentially more powerful adversary. \looseness=-1

%We formulate surveillance strategy synthesis as the problem of computing a winning strategy for the agent in a partial-information game with a surveillance objective. 
There is a rich theory on partial-information games with LTL objectives~\cite{DoyenR11,Chatterjee2013}, and it is well known that, in general, the synthesis problem is EXPTIME-hard~\cite{Reif84,BerwangerD08}. Moreover, all the standard algorithmic solutions to the problem are based on some form of \emph{belief-set construction}, which transforms the \emph{imperfect}-information game into a \emph{perfect}-information game. However, the new set of states in the perfect-information game is the powerset of the original state space in the imperfect-information game. Thus, such approaches scale poorly in general, and are not applicable in most practical situations.

We address the state-space explosion problem from the belief-set construction by using \emph{abstraction}. We introduce an \emph{abstract belief-set construction}, which under-approximates the information-tracking abilities of the agent (or, alternatively, over-approximates its belief, i.e., the set of positions it knows the target could be in). Using this construction we reduce surveillance synthesis to a two-player perfect-information game with an LTL objective, which we then solve using off-the shelf reactive synthesis tools~\cite{EhlersR16}. The abstract belief-set construction guarantees that the abstraction is sound, that is, if a surveillance strategy is found in the abstract game, it corresponds to a surveillance strategy for the original game. If, on the other hand, such a strategy is not found, then the method automatically checks if this is due to the coarseness of the abstraction, in which case the abstract belief space is automatically refined. Thus, the method follows the general counterexample-guided abstraction refinement (CEGAR)~\cite{ClarkeGJLV00} scheme, which has successfully demonstrated its potential in formal verification and synthesis.

{\bf Contributions.}  This paper makes the following contributions:\\
(1) We present a novel framework for encoding \emph{quantitative surveillance} and other task requirements against adversarial agents and synthesising strategies that satisfy the given requirements.\\
(2) This framework is capable of handling \emph{uncertainty in sensor outputs} as well as \emph{multiple sensor modalities}, and it can hence incorporate realistic scenarios from surveillance applications.  \\
(3) We design a belief abstraction approach to solve the partial-information game and develop an algorithm that \emph{automatically refines a given abstraction} in order to improve its precision when no surveillance strategy exists due to coarseness of the approximation.\\
(4) We implement and execute the synthesized surveillance strategies in multiple \emph{high-fidelity simulation} environments and thus demonstrate the adaptability and practical viability of the approach in realistic robotics applications.



{\bf Related work.}
While closely related to the surveillance problem we consider, pursuit-evasion games with partial information~\cite{Chung2011, Chin2010, Antoniades2003} formulate the problem as eventual detection, and do not consider combinations with other mission specifications. Other work, such as \cite{Vidal2002} and \cite{Kim2001}, additionally incorporates map building during pursuit in an unknown environment, but again solely for target detection.

Synthesis from LTL specifications~\cite{Pnueli1989}, especially from formulae in the efficient GR(1) fragment~\cite{Piterman2006}, has been extensively used in robotic planning (e.g.~\cite{wong2012,Kress2007}), but surveillance-type objectives, such as the ones we study here, have not been considered so far. Epistemic logic specifications~\cite{MeydenV98} can model the knowledge of the agent on the truth-value of logical formulas, however, contrary to the surveillance specifications in this paper, they are not capable of expressing requirements on the size of the agent's uncertainty.

CEGAR has been developed for verification~\cite{ClarkeGJLV00}, and later for control~\cite{HenzingerJM03}, of LTL specifications. 
It has also been extended to infinite-state partial-information games~\cite{DimitrovaF08}, and used for sensor design~\cite{FuDT14}, both in the context of safety specifications. In addition to being focused on safety objectives, the refinement method in~\cite{DimitrovaF08} is designed to provide the agent with just enough information to achieve safety, and is thus not applicable to surveillance properties whose satisfaction depends on the size of the belief sets.

This paper generalizes the method presented in~\cite{bharadwaj2018synthesis} and ~\cite{bharadwaj2018distributed} to allow for uncertainty in sensor measurements and multiple sensor modalities. More precisely, we consider sensors that return sets of possible values (for example the set of possible positions of the target whose likelihood is above some given threshold), and include static sensors in addition to the mobile agent. Additionally, we present an automated counterexample-guided abstraction refinement algorithm, while previous work relied solely on user-provided abstractions. Finally, this paper presents simulations on ROS/Gazebo, and Unreal Engine 4 with agents reacting in real-time to a human-controlled adversary.

The rest of the paper is structured as follows. In section II we present a case study to motivate the work in this paper in the context of a real-world security application. In section III we provide definitions and notations for partial-observation games and the encoding of the surveillance requirement as safety and liveness objectives in LTL. In section IV, we present the belief set abstraction in reducing the partial information game to a full information game. In sections V and VI we detail the CEGAR process for the different types of surveillance objectives. In section VII, we demonstrate the framework on gridworld examples to illustrate how abstract belief states are constructed and refined. In section VIII, we implement the surveillance strategy synthesis procedure using Gazebo/ROS as well as unreal engine on robot platforms with simulated LiDAR sensors. Lastly, we conclude and outline future directions in section IX.  



%Performing surveillance on an adversarial target, by its very nature, is a partial information problem. The agent may not always know the position of the target. However, surveillance in conjunction with a mission specification can be crucial in applications such as defense where it is important to keep track of (potentially hostile) targets whilst trying to satisfy a particular objective. 

%Since we are dealing with an adversarial target, a natural setting for formulating the problem is a two-player game. There are several flavours of partial information games that have been studied in the literature \cite{Chatterjee2013}, and in this paper we focus on turn-based one-sided partial-observation deterministic games on which we perform reactive control synthesis. It is one-sided as we allow the adversary full information on the location of the agent even if it is not in sight. 

%Related work in dealing with surveillance type objectives are pursuit-evasion games. There are several methods in formulating the problem such as enforcing eventual detection (at which point the game ends) \cite{Chen2010} or not allowing the target to move more than a certain distance away (\cite{keylist}). Partial information version of these games have also been studied in \cite{Antoniades2003,keylist} where it is shown that there is no existence theory for optimal solutions. However, these approaches treat the surveillance requirement as a search problem - once the target is detected the game is over. Work done by \cite{Vidal2002} and \cite{Kim2001} also include map building during pursuit but again with the sole purpose of target detection. Additionally, we do not enforce the requirement that the target(s) be detected. It is sufficient if we are able to bound our belief of the location below a user specified threshold for an infinite execution which allows for more richer, and more complex, behaviour than standard pursuit-evasion. So while there is work in pursuit-evasion games with partial information \cite{Chen2010} and even unknown environments \cite{Vidal2002}, these do not deal with additional mission specifications and also do not allow for the target to 'escape' and be recaptured as will be necessary in a setting with objectives beyond only capture.

%Our aim is to then synthesize a reactive controller that satisfies both the LTL specification as well as the surveillance objective. While it has been shown that for a general LTL specification, the synthesis problem is doubly exponential in the length of the formula \cite{Pnueli1989}, the work in \cite{Piterman2006} lays out a class of formulae called GR(1) that is $\mathcal{O}(N^3)$. This framework has been used extensively in robotic planning, for example in \cite{wong2012,Kress2007} and we do so here as well. We explicitly encode the surveillance requirement into the GR(1) formula to allow us to exploit the fast nature of GR(1) synthesis to solve a pursuit-evasion game. 

%However, we still have the issue of partial obsno ervability in our setting. The controller will need to choose actions even when the state of the adversary is not known. The standard approach to deal with the partial observability is by using a \emph{belief set construction} to reduce the problem to a full observability game \cite{Bertoli2006}. However, the number of belief states will be exponential in the number of states \cite{Rintanen2004} as the belief set construction takes a powerset of the number of states. In general, this scales poorly and is not usable in most practical situations. \todo{literature on other partial information reduction heuristics}. In this paper, to deal with this problem, we introduce \emph{abstract belief set construction}. This is an underapproximation of the true belief space and hence, if a controller is found, then we know a controller will exist in the fully refined belief space. If a controller is not found, we use counterexample guided abstract refinement (CEGAR) to split a belief set and the process is repeated. While CEGAR has been extensively used on abstract models for GR(1) reactive synthesis \cite{Alur2015,keylist}, to our knowledge it has not been used on belief state refinement in reducing a partial information game to a full information game. 

%The focus of this paper is to solve a modified pursuit-evasion game with additional LTL objectives in a partial information setting using reactive control synthesis. We propose a novel encoding of the surveillance requirement into the GR(1) specification to allow for assume guarantee control synthesis as well as a CEGAR approach in belief set construction in solving the partial information game. Our contributions in this paper are as follows:
%\begin{itemize}
%\item We encode the surveillance task as a safety specification which forces the agent to more closely follow the adversary in order to ensure the uncertainty (size of the belief set) on the location of adversary does not grow above the constraint.
%\item We also encode surveillance task as a liveness objective. This allows for the agent to be more relaxed in monitoring the location of the agent if it can ensure that it can see it again sometime in the future.
%\item We analyse the qualitatively different behaviour produced based on the specification type which allows the user to tailor the specification based on the requirements of the mission.
%\item Avoiding the state space blow up by abstract belief set construction and using counter example guided belief refinement for both the safety and liveness specification cases.
%\end{itemize}

%The rest of the paper is structured as follows. In section II we provide definitions and notations for partial-observation games and the encoding of the pursuit-evasion requirement as safety and liveness objectives in LTL. In section III, we present our belief set abstraction in reducing the partial information game to a full information and also detail the CEGAR process for the different types of objectives. In section IV we provide experiments on gridworlds along with a simulation in ROS using our proposed algorithm, and we conclude and provide future direction in section V. 
