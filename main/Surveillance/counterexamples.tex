Due to the overapproximation of belief sets in the construction of an abstract game structure $G_\abstr$,
a winning strategy for the target in the abstract game does not necessarily correspond to a winning strategy for the target in the concrete belief-set game. When a winning strategy for the target is only the result of the approximation, we call it a \emph{spurious counterexample}. In this and the next section we describe procedures which, given a winning strategy for the target in $(G_{\abstr},\varphi)$, analyze this strategy to determine if it is a spurious counterexample, and when this is the case, automatically refine the abstraction partition in order to eliminate this counterexample strategy from the abstract game constructed using the refined abstraction partition.

In this section we focus on safety surveillance objectives, in the next section we discuss liveness objectives, and finally we consider general surveillance and task specifications.