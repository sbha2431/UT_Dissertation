\chapter{Introduction}

\paragraph{Assurance is the key to unlocking autonomy} Over the last decade, there has been an explosion in the capabilities of autonomous systems and artificial intelligence. While autonomous systems are becoming more tightly integrated into our daily lives, there is still a gap between their technological capabilities and their actual impact. The use of autonomous systems today provide just a glimpse of the potential that the broader deployment of autonomy in society has to drive economic growth and productivity. 

However, the growing scale of impact of autonomous systems in society means that the consequences of the failure of these systems are correspondingly large. Guaranteeing safety and reliability for increasingly complex systems only grows more challenging whilst simultaneously becoming more crucial for their adoption in society. Studies have shown that user concerns over safety, and more broadly, \emph{lack of trust that the system will meet expectations} remains the most significant barrier to deployment for autonomous systems~\cite{KAUR201887,BEZAI202165,MOLNAR2018319}.  

Broad adoption of autonomous systems can provide solutions for emerging societal issues such as congestion~\cite{LIORIS2017292,8734238}, smart urban planning~\cite{GULSRUD201885,NITOSLAWSKI2019101770}, climate change~\cite{KOLOKOTSA2017101,goddard2021global}, and many others~\cite{DUONG2020355}. It is thus necessary to \emph{provably guarantee} to regulators and build trust with consumers that the risk of failure is minimal. Hence, there is a strong need to develop systematic approaches to verify that autonomous systems will comply with all regulations, keep humans safe, and achieve their missions. \emph{Assured autonomy}, where an autonomous system is formally and provably guaranteed to meet precisely stated objectives, is the key to unlocking the full impact that autonomy can bring to our society. 

Assured autonomy has attracted immense interest from government, industry, and academia. It is being widely studied in various contexts as they relate to autonomy including perception, control, learning, motion-planning and decision-making. The focus of the work in this dissertation is on \emph{assured decision-making}. While this concept will be more formally explained in the following sections, we informally state here that assured decision-making is the problem of guaranteeing that the decisions made by an autonomous system will lead to the specified outcome. The following sections will formally lay out how to model the decision-making process of an autonomous agent, and the methods by which we assure the decisions lead to desired outcomes. 


\section{What is decision-making?}

The decision-making process for an autonomous agent is shown in Figure~\ref{fig:decisionloop}. The agent must use its sensors to \emph{observe} the state of the environment. It then processes the information and makes a \emph{decision} to perform an action which its control surfaces must enact.
\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{Introduction/Figs/decisionloop}
	\caption{Simplified process illustration for an autonomous system interacting with the environment.}\label{fig:decisionloop}
\end{figure}


The goal of the decision-making module is to use the information from the sensors to \emph{decide} what action the autonomous agent must make that its control actuators can feasibly implement in order to achieve some higher-level objective. 

This dissertation addresses the following research questions in the context of decision-making:

\begin{itemize}
	\item \emph{How can we specify complex tasks to autonomous agents in a formal but intuitive way with quantitative performance guarantees?}
	\item \emph{How can we provide provable guarantees on the abilities of autonomous agents to carry out these complex tasks?}
	\item \emph{How can users qualitatively tune the behaviour of the agents carrying out these tasks?}
\end{itemize}


\subsection{Decision-making in the autonomy stack}


Most complex autonomous systems are made up of several modules designed by different teams. For example, perception, controls, path-planning, decision-making can all be different parts of the stack. It is thus important that any decision-making module fit in the architecture of an autonomy stack without requiring the full implementation details of the rest of the system. For example, the module must not rely on the precise sensors or algorithms used in the perception stack. In my work, I show that the assurance processes are designed \emph{agnostic} to the specifics of the other modules. The goal of my work is to \emph{assure} that the decison-making method (shown in the red-box in Figure~\ref{fig:decisionloop}) is guaranteed to lead to the specified outcome.  

The decision-making method must of course take into account the capabilities of the sensors and actuators in order to ensure the decisions it makes are actually feasible to implement. For example, in Chapter~\ref{sec:SurveiilanceChapter}, I discuss my work on autonomous surveillance where the agent cannot always sense the location of the adversaries. The work I will present focuses on the case where there is some characterization of the sensing and control capabilities (or lack thereof) and how to guarantee the decisions made with that understanding will lead to the specified objectives. We note for emphasis, that the algorithms provided in this dissertation, do not depend on the specific characterizations of the capabilties - the guarantees change based on what the system is able to feasibly implement. 

\section{Specifying objectives}

Formally specifying precise, verifiable outcomes for the behaviours of autonomous systems is a challenging task. The challenge is further exacerbated by the fact that it will be necessary for non-expert users to interact with and direct increasingly autonomous systems. Non-expert users will need to specify complex tasks to autonomous agents in a precise, but intuitive way, while additionally being able to direct qualitative behavior. 

To illustrate this concept, take for example, an autonomous home vacuum cleaner. The owner may want to issue instructions to vacuum the entire home and additionally specify the order in which the rooms are cleaned. In this example, the owner can state a precise outcome - \emph{vacuum the entire home}, and then tune qualitative behavior of the agent in achieving the outcome - \emph{clean the kitchen first, then the living room, then the bedroom}. 

Furthermore, the ability for non-expert users to specify and tune high-level behavior is crucial from the context of regulation and certificiation. For more complex autonomous systems such as autonomous vehicles or aircraft to be deployed, regulations (written in natural language) must be shown to be adhered to. For example, a regulator may require verification that \emph{no more than X drones are allowed to occupy Y region of airspace}. Again, this is a high-level requirement that the autonomous system must verifiably follow. 

There is not one-size-fits-all approach to formal objective specification. Different applications will have different approaches that are best suited for them. The work in this dissertation relies on the specification provided in temporal logic. I argue that, while this is still a mathematical representation, it is significantly more intuitive to handle compared to manually engineering reward functions (which is standard practice in the AI domain). The long-term goal for assurance is to be able to assure objectives provided in natural language, but that is outside the scope of this dissertation. 

%Of course, this statement leads to questions like: \emph{what does it mean when an autonomous sysem makes a decision?} and \emph{how does one "specify" an outcome?}. These questions have different answers based on the specifics of the context in which they are being asked. I will 




%In order for autonomous systems to become more tightly integrated in society, they will need to be able to handle tasks with increasing levels of complexity. Furthermore, it will be necessary for these systems to interact with non-expert users. As human reliance on autonomy grows, it is also necessary to have \emph{guarantees} on the abilities of these systems to achieve their missions. In this context, we are interested in the following questions:
%\begin{itemize}
%	\item \emph{How can we specify complex tasks to autonomous agents in a formal but intuitive way with quantitative performance guarantees?}
%	\item \emph{How can we provide provable guarantees on the abilities of autonomous agents to carry out these complex tasks?}
%	\item \emph{How can users qualitatively tune the behaviour of the agents carrying out these tasks?}
%\end{itemize}





\section{Assurance through synthesis}

Testing and simulation are logical methods in determining the safety of an autonomous systems. For example, makers of self-driving cars rely on test-driving their cars in real traffic and gathering data. However, studies have shown that the amount of real-world testing needed to truly be confident in a system's safety is not practical and have called for more \emph{innovative methods of demonstrating safety and reliability}~\cite{KALRA2016182}. 

This dissertation draws from the field of \emph{formal methods} to provide formal guarantees. Techniques from formal methods have been widely used in software verification with great success. These techniques are being increasingly applied to autonomous robotics systems. However, there are several challenges that limit the use of formal methods in robotics and autonomy which are detailed in~\cite{10.1145/3342355}. The reader should refer to ~\cite{10.1145/3342355} for full details, but in short, issues such as objective specification, environment modelling, and multi-agent systems are all open challenges in the use of formal methods in assuring autonomous systems. Often, these issues are domain-specific and there is no generalized solution. This dissertation, while requiring some domain-specific modeling (i.e., in Part III for urban air mobility), provides solutions for general theoretical problems such as guarantees under partial-information and safety in multi-agent settings and demonstrate the results in specific applications. 

Broadly, we can provide assurances either by \emph{verifying} a system adheres to specifications or by \emph{synthesizing} the system from the specification that guarantees correctness. Both methods are widely applied in different areas, but this dissertation focuses on \emph{synthesis} based approaches. This is because one drawback of verification methods is that it cannot construct a new system if the existing system does not meet the given specifications. Synthesis, on the other hand, is \emph{correct-by-construction}, i.e., it constructs a system directly from the given specifications that is guaranteed to be correct. However, synthesis techniqes suffer from scalability concerns that limit its ability to be employed in more realistic settings, especially those involving partial-information or multiple agents. Often, abstraction techniques and decentralized architectures are necessary for synthesis techniques to be computationally feasible. This dissertation presents research on employing scalable synthesis approaches to generating complex systems with guarantees of correctness with respect to specifications. In particular, it shows how these techniques can be instrumental in providing a systematic and rigorous pathway to certification and deployment of increasingly autonomous systems in safety-critical contexts.  


\section{Assured autonomy for urban air mobility} One application area in which autonomy is poised to make a fundamental impact is urban air mobility (UAM). Mass transportation of both passengers and cargo using increasingly autonomous air vehicles in metropolitan areas is an imminent possibility. For such an expansive vision to be realized, there are a significant number of technical challenges to be addressed.  First and foremost is the issue of safety. With projections indicating high-volume use of autonomous aircraft in urban air spaces, it is clear that advances in decision-making for autonomous systems with \emph{assured performance} will play a key role in the advancement and acceptance of UAM. Furthermore, any such technical solution must be able to handle the envisioned massive scale of operations as well as communication and sensing restrictions. Second, in any large-scale operations involving autonomy, it will be necessary for non-expert users to interact with and direct increasingly autonomous systems. However, specifying a complex mission is no trivial task and can often require extensive tuning and expertise. 

\section{Dissertation overview}

This dissertation employs an interdisciplinary approach to address the technical challenges of assuring autonomy for large-scale complex systems. Specifically, it uses techniques that draw from formal methods, learning theory, and controls. The field of formal methods is a powerful tool for providing guarantees on performance and safety. However, it suffers from a lack of scalability, restricting its use in partial-information or multi-agent settings. this dissertation presents algorithms that leverage the guarantees of formal methods with the efficiency of techniques in controls and learning to perform complex missions with provable guarantees in large environments. Providing high-level mission guarantees in such settings was previously beyond the reach of standard approaches in formal methods due to state-space explosion and lack of automated techniques. This dissertation will showcase both theoretical guarantees of safety and performance, but also real-world applicability with high-fidelity simulations and hardware testing. 

As mentioned earlier, the key focus of this dissertation is in employing synthesis-based methods for assured decision-making. In particular, the focus will be on realistic systems where standard synthesis approaches cannot scale. There are two particular areas in which this dissertation will provide theoretical contributions to allow for synthesis for assurance. First, this dissertation studies \emph{partial-information} settings. Verification and synthesis in with partial-information, ie.., where parts of the state space are not always observable, are well known to be computationally intractable~\cite{Baier2009ModelCL}, and providing assurances in models such as POMDPs is by an large an open problem~\cite{partialinfoltl}. Much of the work for synthesis in partially-observable settings relies on restrictive assumptions and formulations~\cite{6426524,6426174}. Refer to chapter 2 for a more detailed discussion of related work. This dissertation provides an automated \emph{belief-abstraction} method to generate provably sound abstractions and corresponding strategies that guarantee given user requirements. 

Second, this dissertation looks at assurance in \emph{multi-agent} settings. This setting has been widely studied in the literature and scalability issues limits the application of synthesis techniques for assurance. Refer to chapters 4 and 5 for more detailed discussion on the relevant related works. The main contribution of this dissertation is in the use of \emph{runtime assurance} in multi-agent settings. Specifically, the contributions are two-fold. It is the first to study the concept of \emph{quantitative shielding}, i.e., minimizing an interference cost function while still guaranteeing safety at runtime. However, this work suffers from scalability concerns which is addressed in by the second contribution detailed in chapter 5 by providing a decentralized algorithms with guarantees of fairness and correctness. 

As driving idea of this dissertation is extending synthesis techniques for assurance in large-scale complex systems, the application area of urban air mobility is a natural fit to showcase the viability of the proposed techniques. Urban air mobility is still in its infancy and it is limited by lack of knowledge on how to provide scalable assurances in such a safety critical industry. See chapter 6 for the detailed literature review. This dissertation paves the way for the deployment of urban air mobility by providing a synthesis architecture that can provide system-level guarantees in a scalable manner. There is no other work that can provide both the scalability needed for the envisoned scope of operations of urban air mobility as well as the formal guarantees that would be needed by regulators for certification and deployment. 



\subsection{Structure}

The dissertation is divided into 3 parts. Part I presents work on \emph{design-time synthesis}. Specifically, Chapter 2 focuses on the application area of autonomous surveillance against adversarial moving targets. Chapter 3 presents work on incorporating information gained at runtime into design-time synthesis to improve performance while still providing guarantees of correctness. 

Part II discusses \emph{multi-agent runtime assurance}. Chapter 4 will introduce and solve the problem of quantitative shielding for runtime assurance in multi-agent settings. Chapter 5 provides a decentralized approach which we directly compare to the work in chapter 4 to show much improved scalability. 

Part III combines the contributions from Parts I and II into assurance methods for traffic management in urban air mobility. It shows how both design-time synthesis as well as multi-agent runtime assurance can be used in order to design a synthesis architecture that can scalably guarantee safe operations for urban air mobility. 

The dissertation concludes in chapter 8 with some discussion on the limitations on the presented work and some thoughts on future research direction. 

% Metropolitan areas (other areas more scope)
%%%% Combine is too weak 
%% Learning theory 


